{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dataset Creation Jupyter Notebook\n",
    "This is where the code for the processing of data and the creation of the dataset for phenophase classification will reside.\n",
    "\n",
    "Two important parts of this: \n",
    "(1) finding average transition dates for each site and each year\n",
    "(2) storing this data in a readable JSON format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def date_to_doy(date):\n",
    "    year = int(date[:date.find('-')])\n",
    "    adjusted_input = date[date.find('-')+1:]\n",
    "    month = int(adjusted_input[:adjusted_input.find('-')])\n",
    "    day = int(adjusted_input[adjusted_input.find('-')+1:])\n",
    "\n",
    "    dates_in_prev_months = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334] #index 0 is jan, 1 is feb etc.\n",
    "    doy = dates_in_prev_months[month - 1] + day\n",
    "    \n",
    "    if year % 4 == 0 and (year % 100 != 0 or year % 400 == 0) and month > 2:\n",
    "        doy += 1\n",
    "\n",
    "    return doy, year\n",
    "\n",
    "def doy_to_date(doy, year):\n",
    "    leap_year = year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "    dates_in_prev_months = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334] #index 0 is jan, 1 is feb etc.\n",
    "    dates_in_prev_months_lyr = [0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]\n",
    "\n",
    "    month = 0\n",
    "    day = 1\n",
    "\n",
    "    for i in range(len(dates_in_prev_months)):\n",
    "        if leap_year:\n",
    "            if i == 11:\n",
    "                month = 12\n",
    "                day = doy - dates_in_prev_months_lyr[i]\n",
    "                return year, month, day\n",
    "\n",
    "            elif doy > dates_in_prev_months_lyr[i] and doy <= dates_in_prev_months_lyr[i+1]:\n",
    "                month = i + 1\n",
    "                if month >= 2:\n",
    "                    day = doy - dates_in_prev_months_lyr[i]\n",
    "                else: \n",
    "                    day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "        else:\n",
    "            if i == 11:\n",
    "                month = 12\n",
    "                day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "            elif doy > dates_in_prev_months[i] and doy <= dates_in_prev_months[i+1]:\n",
    "                month = i + 1\n",
    "                day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "        \n",
    "    return year, month, day\n",
    "\n",
    "def calc_average_transition_date(str_dates_list, is_rising):\n",
    "    years = []\n",
    "    doys = []\n",
    "    for string in str_dates_list:\n",
    "        doy, year = date_to_doy(string)\n",
    "        doys.append(doy)\n",
    "        years.append(year)\n",
    "    avg_year = int(statistics.median(years))\n",
    "    avg_doy = int(statistics.median(doys))\n",
    "    _, avg_month, avg_day = doy_to_date(avg_doy, avg_year)\n",
    "    date = str(avg_year) + '_' + str(avg_month) + '_' + str(avg_day)\n",
    "\n",
    "    return {'rising':is_rising, 'date':date , 'year':avg_year, 'month':avg_month, 'day':avg_day, 'doy':avg_doy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract all transition dates from CSV files, then caculate median date, and save the respective transition dates for each to a JSON file\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "directory = \"./phenocam_data/\"\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".csv\")]\n",
    "\n",
    "for file in filtered_files:\n",
    "    path_to_file = os.path.join(directory, file)\n",
    "    sitename = file[:file.find('_')]\n",
    "\n",
    "    df = pd.read_csv(path_to_file, index_col=False)\n",
    "    df_lists = df.values.tolist()\n",
    "    \n",
    "    num_rising = 0\n",
    "    num_falling = 0\n",
    "    for list in df_lists:\n",
    "        if 'rising' in (string for string in list): \n",
    "            num_rising += 1\n",
    "        elif 'falling' in (string for string in list): \n",
    "            num_falling += 1 \n",
    "\n",
    "    num_rising_transitions = int(num_rising / 4)\n",
    "    num_falling_transitions = int(num_falling / 4)\n",
    "\n",
    "    rising = [[] for _ in range(num_rising_transitions)]\n",
    "    falling = [[] for _ in range(num_falling_transitions)]\n",
    "\n",
    "    i = 0\n",
    "    for list in df_lists:\n",
    "        if 'rising' in (string for string in list): \n",
    "            rising[i].extend(list[5:14])\n",
    "            i += 1\n",
    "            if i==num_rising_transitions: i=0\n",
    "        elif 'falling' in (string for string in list): \n",
    "            falling[i].extend(list[5:14])  \n",
    "            i += 1\n",
    "            if i==num_falling_transitions: i=0\n",
    "    \n",
    "    avg_transitions = [calc_average_transition_date(transition, True) for transition in rising]\n",
    "    avg_transitions.extend([calc_average_transition_date(transition, False) for transition in falling])\n",
    "\n",
    "    transition_date_data = {\n",
    "        'sitename': sitename,\n",
    "        'transitions': avg_transitions,\n",
    "    }\n",
    "\n",
    "    file_to_save = sitename + '_transition_dates.json'\n",
    "    path_to_target = os.path.join(directory, file_to_save) \n",
    "    with open(path_to_target, 'w') as f:\n",
    "        json.dump(transition_date_data, f, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method, given input of img_file, output boolean indicating if rising or falling\n",
    "def is_rising(filename):\n",
    "    truncated_filename = filename[filename.rfind('/')+1:]\n",
    "    sitename = truncated_filename[:truncated_filename.find('_')]\n",
    "    date = truncated_filename[truncated_filename.find('_')+1:-11].replace('_', '-')\n",
    "    doy, year = date_to_doy(date)\n",
    "    total_days = 365.2422 * year + doy\n",
    "\n",
    "    # load json transition dates file\n",
    "    with open('./phenocam_data/' + sitename + '_transition_dates.json', 'r') as file:\n",
    "         site_transitions =  json.load(file)['transitions']\n",
    "\n",
    "    # find closest\n",
    "    distances = []\n",
    "    for i in range(len(site_transitions)):\n",
    "        year_trans = site_transitions[i]['year']\n",
    "        doy_trans = site_transitions[i]['doy']\n",
    "        total_days_trans = 365.2422 * year_trans + doy_trans\n",
    "        distance = total_days - total_days_trans\n",
    "        distances.append((i, distance))\n",
    "    \n",
    "    closest = min(distances, key=lambda x: x[1])\n",
    "    if site_transitions[closest[0]]['rising']:\n",
    "        return closest[1] >= 0\n",
    "    else:\n",
    "        return closest[1] < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pred truth is_right\nTrue False False\nTrue False False\nTrue False False\nTrue False False\nTrue True True\nFalse True False\nTrue True True\nTrue True True\nTrue True True\nTrue True True\nTrue False False\nTrue False False\nTrue False False\nTrue idk False\nTrue False False\nTrue False False\n"
     ]
    }
   ],
   "source": [
    "# test cases for is_rising()\n",
    "test_files = {\"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2011_11_05_120104.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2012_10_06_120103.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2013_01_07_120102.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2014_12_09_120103.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2012_08_10_120104.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2019_06_11_120104.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2013_07_12_120104.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2012_05_13_120923.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2016_04_05_120104.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2012_04_06_120103.jpg\":True,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2013_02_07_120102.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2014_01_09_120103.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2015_11_10_120104.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2011_11_12_120104.jpg\":False,\n",
    "        \"../PhenoCam_v2/images/willowcreek_phenocam_data_20201202041945/phenocamdata/willowcreek/2011/11/willowcreek_2011_11_13_120923.jpg\":False} # not all exist\n",
    "\n",
    "print('pred truth is_right')\n",
    "for test_file in test_files.items():\n",
    "    print(is_rising(test_file[0]), test_file[1], is_rising(test_file[0])==test_file[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort images into \"sorted_images\" folder according to rising or falling\n",
    "from PIL import Image\n",
    "directory = \"./phenocam_data/\"\n",
    "target_directory = '../PhenoCam_v2/sorted_images/'\n",
    "\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\"imgs.json\")]\n",
    "\n",
    "print(\"Started sorting!\")\n",
    "for file in filtered_files:\n",
    "    with open(directory + file, 'r') as f:\n",
    "        img_list = json.load(f)['img_file_names']\n",
    "    for img_filename in img_list:\n",
    "        filename = img_filename[img_filename.rfind('/')+1:] \n",
    "        if is_rising(img_filename):\n",
    "            img = Image.open(img_filename)\n",
    "            img.save(target_directory + 'rising/' + filename)\n",
    "        else:\n",
    "            img = Image.open(img_filename)\n",
    "            img.save(target_directory + 'falling/' + filename)\n",
    "    i = 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into data folder as needed for dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick test cnn to see if it works (using imagedatagenerator)\n"
   ]
  }
 ]
}