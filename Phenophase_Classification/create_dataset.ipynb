{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Dataset Creation Jupyter Notebook\n",
    "This is where the code for the processing of data and the creation of the dataset for phenophase classification will reside.\n",
    "\n",
    "Two important parts of this: \n",
    "(1) finding average transition dates for each site and each year\n",
    "(2) storing this data in a readable JSON format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def date_to_doy(date):\n",
    "    year = int(date[:date.find('-')])\n",
    "    adjusted_input = date[date.find('-')+1:]\n",
    "    month = int(adjusted_input[:adjusted_input.find('-')])\n",
    "    day = int(adjusted_input[adjusted_input.find('-')+1:])\n",
    "\n",
    "    dates_in_prev_months = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334] #index 0 is jan, 1 is feb etc.\n",
    "    doy = dates_in_prev_months[month - 1] + day\n",
    "    \n",
    "    if year % 4 == 0 and (year % 100 != 0 or year % 400 == 0) and month > 2:\n",
    "        doy += 1\n",
    "\n",
    "    return doy, year\n",
    "\n",
    "def doy_to_date(doy, year):\n",
    "    leap_year = year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)\n",
    "    dates_in_prev_months = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334] #index 0 is jan, 1 is feb etc.\n",
    "    dates_in_prev_months_lyr = [0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]\n",
    "\n",
    "    month = 0\n",
    "    day = 1\n",
    "\n",
    "    for i in range(len(dates_in_prev_months)):\n",
    "        if leap_year:\n",
    "            if i == 11:\n",
    "                month = 12\n",
    "                day = doy - dates_in_prev_months_lyr[i]\n",
    "                return year, month, day\n",
    "\n",
    "            elif doy > dates_in_prev_months_lyr[i] and doy <= dates_in_prev_months_lyr[i+1]:\n",
    "                month = i + 1\n",
    "                if month >= 2:\n",
    "                    day = doy - dates_in_prev_months_lyr[i]\n",
    "                else: \n",
    "                    day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "        else:\n",
    "            if i == 11:\n",
    "                month = 12\n",
    "                day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "            elif doy > dates_in_prev_months[i] and doy <= dates_in_prev_months[i+1]:\n",
    "                month = i + 1\n",
    "                day = doy - dates_in_prev_months[i]\n",
    "                return year, month, day\n",
    "        \n",
    "    return year, month, day\n",
    "\n",
    "def calc_average_transition_date(str_dates_list, is_rising):\n",
    "    years = []\n",
    "    doys = []\n",
    "    for string in str_dates_list:\n",
    "        doy, year = date_to_doy(string)\n",
    "        doys.append(doy)\n",
    "        years.append(year)\n",
    "    avg_year = int(statistics.median(years))\n",
    "    avg_doy = int(statistics.median(doys))\n",
    "    _, avg_month, avg_day = doy_to_date(avg_doy, avg_year)\n",
    "    date = str(avg_year) + '_' + str(avg_month) + '_' + str(avg_day)\n",
    "\n",
    "    return {'rising':is_rising, 'date':date , 'year':avg_year, 'month':avg_month, 'day':avg_day, 'doy':avg_doy}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract all transition dates from CSV files, then caculate median date, and save the respective transition dates for each to a JSON file\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "directory = \"./phenocam_data/\"\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\".csv\")]\n",
    "\n",
    "for file in filtered_files:\n",
    "    path_to_file = os.path.join(directory, file)\n",
    "    sitename = file[:file.find('_')]\n",
    "\n",
    "    df = pd.read_csv(path_to_file, index_col=False)\n",
    "    df_lists = df.values.tolist()\n",
    "    \n",
    "    num_rising = 0\n",
    "    num_falling = 0\n",
    "    for list in df_lists:\n",
    "        if 'rising' in (string for string in list): \n",
    "            num_rising += 1\n",
    "        elif 'falling' in (string for string in list): \n",
    "            num_falling += 1 \n",
    "\n",
    "    num_rising_transitions = int(num_rising / 4)\n",
    "    num_falling_transitions = int(num_falling / 4)\n",
    "\n",
    "    rising = [[] for _ in range(num_rising_transitions)]\n",
    "    falling = [[] for _ in range(num_falling_transitions)]\n",
    "\n",
    "    i = 0\n",
    "    for list in df_lists:\n",
    "        if 'rising' in (string for string in list): \n",
    "            rising[i].extend(list[5:14])\n",
    "            i += 1\n",
    "            if i==num_rising_transitions: i=0\n",
    "        elif 'falling' in (string for string in list): \n",
    "            falling[i].extend(list[5:14])  \n",
    "            i += 1\n",
    "            if i==num_falling_transitions: i=0\n",
    "    \n",
    "    avg_transitions = [calc_average_transition_date(transition, True) for transition in rising]\n",
    "    avg_transitions.extend([calc_average_transition_date(transition, False) for transition in falling])\n",
    "\n",
    "    transition_date_data = {\n",
    "        'sitename': sitename,\n",
    "        'transitions': avg_transitions,\n",
    "    }\n",
    "\n",
    "    file_to_save = sitename + '_transition_dates.json'\n",
    "    path_to_target = os.path.join(directory, file_to_save) \n",
    "    with open(path_to_target, 'w') as f:\n",
    "        json.dump(transition_date_data, f, indent=4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method, given input of img_file, output boolean indicating if rising or falling\n",
    "def is_rising(filename):\n",
    "    truncated_filename = filename[filename.rfind('/')+1:]\n",
    "    sitename = truncated_filename[:truncated_filename.find('_')]\n",
    "    date = truncated_filename[truncated_filename.find('_')+1:-11].replace('_', '-') \n",
    "    doy, year = date_to_doy(date)\n",
    "    total_days = 365.2422 * year + doy\n",
    "\n",
    "    # load json transition dates file\n",
    "    with open('./phenocam_data/' + sitename + '_transition_dates.json', 'r') as file:\n",
    "         site_transitions =  json.load(file)['transitions']\n",
    "\n",
    "    # find closest\n",
    "    distances = []\n",
    "    for i in range(len(site_transitions)):\n",
    "        year_trans = site_transitions[i]['year']\n",
    "        doy_trans = site_transitions[i]['doy']\n",
    "        total_days_trans = 365.2422 * year_trans + doy_trans\n",
    "        distance = total_days - total_days_trans\n",
    "        abs_distance = abs(distance)\n",
    "        distances.append((i, distance, abs_distance))\n",
    "    \n",
    "    closest = min(distances, key=lambda x: x[2])\n",
    "    if site_transitions[closest[0]]['rising']:\n",
    "        return closest[1] >= 0\n",
    "    else:\n",
    "        return closest[1] < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort images into \"sorted_images\" folder according to rising or falling\n",
    "from PIL import Image\n",
    "directory = \"./phenocam_data/\"\n",
    "target_directory = '../PhenoCam_v2/sorted_images/'\n",
    "\n",
    "files_in_directory = os.listdir(directory)\n",
    "filtered_files = [file for file in files_in_directory if file.endswith(\"imgs.json\")]\n",
    "\n",
    "print(\"Started sorting!\")\n",
    "for file in filtered_files:\n",
    "    print(\"Site:\", file[:-10])\n",
    "    with open(directory + file, 'r') as f:\n",
    "        img_list = json.load(f)['img_file_names']\n",
    "    for img_filename in img_list:\n",
    "        filename = img_filename[img_filename.rfind('/')+1:] \n",
    "        if is_rising(img_filename):\n",
    "            img = Image.open(img_filename)\n",
    "            img.save(target_directory + 'rising/' + filename)\n",
    "        else:\n",
    "            img = Image.open(img_filename)\n",
    "            img.save(target_directory + 'falling/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into data folder as needed for dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 80886 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "1264/1264 [==============================] - 1020s 807ms/step - loss: 0.6125 - binary_accuracy: 0.8606 - auc: 0.9339 - precision: 0.8475 - recall: 0.8376\n",
      "Epoch 2/25\n",
      "1264/1264 [==============================] - 1020s 807ms/step - loss: 0.1663 - binary_accuracy: 0.9433 - auc: 0.9841 - precision: 0.9424 - recall: 0.9295\n",
      "Epoch 3/25\n",
      "1264/1264 [==============================] - 1036s 820ms/step - loss: 0.1286 - binary_accuracy: 0.9585 - auc: 0.9899 - precision: 0.9591 - recall: 0.9473\n",
      "Epoch 4/25\n",
      "1264/1264 [==============================] - 1040s 823ms/step - loss: 0.1098 - binary_accuracy: 0.9650 - auc: 0.9921 - precision: 0.9649 - recall: 0.9562\n",
      "Epoch 5/25\n",
      "1264/1264 [==============================] - 1021s 808ms/step - loss: 0.1007 - binary_accuracy: 0.9698 - auc: 0.9938 - precision: 0.9687 - recall: 0.9634\n",
      "Epoch 6/25\n",
      "1264/1264 [==============================] - 1015s 803ms/step - loss: 0.0976 - binary_accuracy: 0.9730 - auc: 0.9948 - precision: 0.9714 - recall: 0.9679\n",
      "Epoch 7/25\n",
      "1264/1264 [==============================] - 1014s 803ms/step - loss: 0.0829 - binary_accuracy: 0.9753 - auc: 0.9953 - precision: 0.9749 - recall: 0.9696\n",
      "Epoch 8/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0833 - binary_accuracy: 0.9777 - auc: 0.9958 - precision: 0.9763 - recall: 0.9736\n",
      "Epoch 9/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0712 - binary_accuracy: 0.9784 - auc: 0.9960 - precision: 0.9772 - recall: 0.9742\n",
      "Epoch 10/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0685 - binary_accuracy: 0.9800 - auc: 0.9963 - precision: 0.9788 - recall: 0.9762\n",
      "Epoch 11/25\n",
      "1264/1264 [==============================] - 1015s 803ms/step - loss: 0.0653 - binary_accuracy: 0.9813 - auc: 0.9965 - precision: 0.9800 - recall: 0.9780\n",
      "Epoch 12/25\n",
      "1264/1264 [==============================] - 1016s 804ms/step - loss: 0.0599 - binary_accuracy: 0.9831 - auc: 0.9968 - precision: 0.9824 - recall: 0.9797\n",
      "Epoch 13/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0569 - binary_accuracy: 0.9833 - auc: 0.9970 - precision: 0.9820 - recall: 0.9805\n",
      "Epoch 14/25\n",
      "1264/1264 [==============================] - 1013s 801ms/step - loss: 0.0643 - binary_accuracy: 0.9843 - auc: 0.9973 - precision: 0.9831 - recall: 0.9817\n",
      "Epoch 15/25\n",
      "1264/1264 [==============================] - 1011s 800ms/step - loss: 0.0517 - binary_accuracy: 0.9849 - auc: 0.9973 - precision: 0.9838 - recall: 0.9823\n",
      "Epoch 16/25\n",
      "1264/1264 [==============================] - 1012s 800ms/step - loss: 0.0470 - binary_accuracy: 0.9858 - auc: 0.9976 - precision: 0.9844 - recall: 0.9837\n",
      "Epoch 17/25\n",
      "1264/1264 [==============================] - 1010s 799ms/step - loss: 0.0630 - binary_accuracy: 0.9862 - auc: 0.9976 - precision: 0.9852 - recall: 0.9836\n",
      "Epoch 18/25\n",
      "1264/1264 [==============================] - 1012s 801ms/step - loss: 0.0438 - binary_accuracy: 0.9876 - auc: 0.9978 - precision: 0.9864 - recall: 0.9858\n",
      "Epoch 19/25\n",
      "1264/1264 [==============================] - 1013s 802ms/step - loss: 0.0453 - binary_accuracy: 0.9877 - auc: 0.9978 - precision: 0.9873 - recall: 0.9850\n",
      "Epoch 20/25\n",
      "1264/1264 [==============================] - 1012s 801ms/step - loss: 0.0448 - binary_accuracy: 0.9884 - auc: 0.9977 - precision: 0.9875 - recall: 0.9864\n",
      "Epoch 21/25\n",
      "1264/1264 [==============================] - 1014s 803ms/step - loss: 0.0399 - binary_accuracy: 0.9885 - auc: 0.9981 - precision: 0.9878 - recall: 0.9864\n",
      "Epoch 22/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0397 - binary_accuracy: 0.9892 - auc: 0.9980 - precision: 0.9882 - recall: 0.9875\n",
      "Epoch 23/25\n",
      "1264/1264 [==============================] - 1013s 802ms/step - loss: 0.0377 - binary_accuracy: 0.9899 - auc: 0.9982 - precision: 0.9892 - recall: 0.9881\n",
      "Epoch 24/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0422 - binary_accuracy: 0.9901 - auc: 0.9981 - precision: 0.9892 - recall: 0.9885\n",
      "Epoch 25/25\n",
      "1264/1264 [==============================] - 1014s 802ms/step - loss: 0.0350 - binary_accuracy: 0.9907 - auc: 0.9982 - precision: 0.9898 - recall: 0.9894\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b211f61520>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# quick test cnn to see if it works (using imagedatagenerator)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, AUC, Precision, Recall, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "# images are of ratio 43:32\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "generator = datagen.flow_from_directory('../PhenoCam_v2/sorted_images/', target_size=(172,128), batch_size=64, shuffle=True, class_mode='binary')\n",
    "\n",
    "#define model (AlexNet)\n",
    "model = Sequential([\n",
    "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(172, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy(), metrics=[BinaryAccuracy(threshold=0.5), AUC(), Precision(), Recall()])\n",
    "\n",
    "# train model\n",
    "model.fit(generator, epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'loss': [0.6125330924987793, 0.1662815660238266, 0.12858790159225464, 0.10977417975664139, 0.10066010802984238, 0.09756798297166824, 0.08290881663560867, 0.0832868292927742, 0.07117212563753128, 0.06848951429128647, 0.06527780741453171, 0.05994107946753502, 0.05693945288658142, 0.06434836238622665, 0.05165260657668114, 0.0469704233109951, 0.06303497403860092, 0.04378298670053482, 0.045311059802770615, 0.044785454869270325, 0.03991076350212097, 0.03972787410020828, 0.03765932843089104, 0.042242471128702164, 0.035044606775045395], 'binary_accuracy': [0.860569179058075, 0.9432905316352844, 0.9585465788841248, 0.9650001525878906, 0.9698340892791748, 0.9729990363121033, 0.9753356575965881, 0.9777217507362366, 0.9784017205238342, 0.9799841642379761, 0.9813070297241211, 0.9831243753433228, 0.9833098649978638, 0.9843359589576721, 0.9849293828010559, 0.9857948422431946, 0.9861533641815186, 0.9875998497009277, 0.9876863956451416, 0.9883910417556763, 0.9884899854660034, 0.9891946911811829, 0.9899117350578308, 0.9900724291801453, 0.9907400608062744], 'auc': [0.9339380860328674, 0.9841383695602417, 0.9899086356163025, 0.9920758008956909, 0.9938479661941528, 0.9948344230651855, 0.9953179359436035, 0.9958475828170776, 0.9960163831710815, 0.9962789416313171, 0.9965020418167114, 0.9968183040618896, 0.9970173239707947, 0.997304379940033, 0.997260332107544, 0.9976464509963989, 0.997612476348877, 0.9977527260780334, 0.9977526664733887, 0.9977471232414246, 0.9980536699295044, 0.9979871511459351, 0.9981850385665894, 0.9981073141098022, 0.9982218146324158], 'precision': [0.8475347757339478, 0.9423802495002747, 0.9591016173362732, 0.9648960828781128, 0.968731701374054, 0.9713839888572693, 0.9749037027359009, 0.9763343334197998, 0.9772195816040039, 0.9787619113922119, 0.9799705147743225, 0.9823775291442871, 0.9819557070732117, 0.9830960631370544, 0.9838440418243408, 0.9843862652778625, 0.9852340221405029, 0.9863873720169067, 0.9872832894325256, 0.9875472784042358, 0.9877669215202332, 0.9881927967071533, 0.9892431497573853, 0.9892470240592957, 0.9898338913917542], 'recall': [0.8375579714775085, 0.9294816851615906, 0.9473055601119995, 0.9561898112297058, 0.9633526802062988, 0.9678780436515808, 0.969571590423584, 0.9735695123672485, 0.9742080569267273, 0.9762347936630249, 0.9780116081237793, 0.9796773791313171, 0.9805380702018738, 0.9817041158676147, 0.9822871088981628, 0.9837030172348022, 0.9836475253105164, 0.9857575297355652, 0.9850356578826904, 0.9863682985305786, 0.9863682985305786, 0.9875343441963196, 0.9880896210670471, 0.9884505271911621, 0.9893667101860046]}\n"
     ]
    }
   ],
   "source": [
    "print(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}